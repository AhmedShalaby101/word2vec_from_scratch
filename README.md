# Word2Vec From Scratch ğŸ§ ğŸ’¬

This project implements a Word2Vec model (skip-gram architecture) **from scratch using PyTorch**. It includes a full training pipeline, dataset preprocessing, and a simple app to visualize word embeddings.

## ğŸš€ Features
- Custom implementation of Word2Vec (skip-gram)
- PyTorch model training and saving
- Data preparation pipeline (raw â†’ processed)
- Embedding visualization interface via `APP.py`
- Modular project structure for easy experimentation

## ğŸ“ Project Structure

```
word2vec_from_scratch/
â”œâ”€â”€ APP.py                  # Front-end interface to explore embeddings
â”œâ”€â”€ Train.py                # Script to train the model
â”œâ”€â”€ word2vec_model.pth      # Saved PyTorch model
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Project README
â”œâ”€â”€ app_screen_shots/       # Screenshots for app usage
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw datasets
â”‚   â”œâ”€â”€ processed/          # Processed training/validation sets
â”‚   â”œâ”€â”€ interim/            # Intermediate mappings (word2id, id2word)
â”‚   â””â”€â”€ external/           # External or third-party data (empty)
â””â”€â”€ docs/                   # Reserved for documentation
```

## ğŸ“¸ Screenshots

App interface samples (from `app_screen_shots/`):

![screenshot1](app_screen_shots/1.png)
![screenshot2](app_screen_shots/2.png)
![screenshot3](app_screen_shots/3.png)
![screenshot4](app_screen_shots/4.png)
![screenshot5](app_screen_shots/5.png)

## ğŸ”§ Installation

```bash
git clone https://github.com/yourusername/word2vec_from_scratch.git
cd word2vec_from_scratch
pip install -r requirements.txt
```

## ğŸ Running the Project

### Train the model

```bash
python Train.py
```

### Launch the App (e.g., Streamlit)

```bash
streamlit run APP.py
```

> âš ï¸ You may need to adjust the paths in the scripts depending on your working directory.

## ğŸ“Š Model

- Architecture: Skip-gram Word2Vec
- Framework: PyTorch
- Embedding size, window size, negative sampling â€“ configurable in `Train.py`

## ğŸ“‚ Dataset

- Preprocessed text data is located in `data/processed`
- Raw text file: `data/raw/raw_dataset.pkl`
- Vocabulary mappings: `data/interim/word2id`, `id2word`

## âœ… TODOs / Future Improvements

- Add CBOW option
- Visualize embeddings with t-SNE or PCA
- Add evaluation metrics

## ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

MIT License

---

*Made with â¤ï¸ by [Your Name]*
